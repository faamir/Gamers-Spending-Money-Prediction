{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KABAM Assignment (Data Scientist Position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlite3 import connect\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU, Bidirectional, Embedding, RepeatVector, TimeDistributed, Flatten\n",
    "import time\n",
    "import keras\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV, Lasso, LassoCV, RidgeCV, Ridge, LarsCV, ElasticNet\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from lazypredict.Supervised import LazyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Two approaches: classification or Regression. Just one should be True\n",
    "classification_mode = True\n",
    "regression_mode = False\n",
    "\n",
    "# if True then downsampling will be done for train data\n",
    "down_sample = False\n",
    "# oversampling can be False, 'random_oversample' or 'smote_oversample'\n",
    "up_sample = 'smote_oversample'\n",
    "# number of classes for classification. 2, 3 or 5 classes for now.\n",
    "n_class = 3\n",
    "\n",
    "if classification_mode:\n",
    "    # int as n_components for PCA or False for no PCA\n",
    "    PCA_apply = False\n",
    "    # drop categorical columns\n",
    "    drop_categorical_cols = False\n",
    "    # if True then label with value of 0 will be removed\n",
    "    drop_zero_calss = True\n",
    "\n",
    "if regression_mode:\n",
    "    # int as n_components for PCA or False for no PCA\n",
    "    PCA_apply = False\n",
    "    # drop categorical columns\n",
    "    drop_categorical_cols = False\n",
    "    # if True then label with value of 0 will be removed\n",
    "    drop_zero_calss = True\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_index(df, index, droped_columns): \n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a new dataframe with the specified index\n",
    "    and remove droped columns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pandas dataframe\n",
    "        The dataframe to be indexed.\n",
    "    index: string\n",
    "        The name of the index column.\n",
    "    droped_columns: list of strings\n",
    "        The list of columns to be dropped.\n",
    "\n",
    "    Returns: pandas dataframe\n",
    "    \"\"\"\n",
    "    df.index = df[index]\n",
    "    df.drop(columns=droped_columns, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ka_actions as dataframe\n",
    "# place datasets into kabam_ds_interview folder or change the path\n",
    "ka_actions = pd.read_parquet('./kabam_ds_interview/ka_actions.parquet')\n",
    "ka_actions = df_index(ka_actions, 'uid_s', ['uid_s'])\n",
    "print(ka_actions.shape)\n",
    "print(\"Number of Nans for each column: \\n\",ka_actions.isna().sum())\n",
    "ka_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ka_users as dataframe\n",
    "ka_users = pd.read_csv('./kabam_ds_interview/ka_users.csv')\n",
    "ka_users = df_index(ka_users, 'uid_s', ['uid_s'])\n",
    "print(ka_users.shape)\n",
    "print(\"Number of Nans for each column: \\n\", ka_users.isna().sum())\n",
    "ka_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chech the name of the tables in ka_devices database.\n",
    "ka_devices_db = connect('./kabam_ds_interview/ka_devices.db')\n",
    "ka_devices_name = pd.read_sql_query(\"SELECT name as table_name FROM sqlite_schema WHERE type ='table' AND name NOT LIKE 'sqlite_%';\", ka_devices_db)\n",
    "ka_devices_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ka_devices as dataframe\n",
    "ka_devices = pd.read_sql_query(\"SELECT * FROM devices\", ka_devices_db)\n",
    "ka_devices = df_index(ka_devices, 'uid_s', ['uid_s', 'index'])\n",
    "print(ka_devices.shape)\n",
    "print(\"Number of Nans for each column: \\n\", ka_devices.isna().sum())\n",
    "ka_devices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all dataframes\n",
    "for df in [ka_devices, ka_actions, ka_users]:\n",
    "    print(f\"Describe dataframe: \\n\", df.describe())\n",
    "    print(df.shape)\n",
    "    print(\"********\"*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all dataframes to have one dataframe with all data\n",
    "df = ka_users.join(ka_devices, on=ka_users.index).join(ka_actions, on=ka_actions.index)\n",
    "print(df.columns)\n",
    "# print((df[df['total_spend']>0].shape[0] / df[df['total_spend']==0].shape[0])*100)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many of each value for game_stats_tutorial_complete\n",
    "unique_game_stats_tutorial_complete = df.game_stats_tutorial_complete.unique()\n",
    "print(unique_game_stats_tutorial_complete)\n",
    "\n",
    "print(f\"Number of game_stats_tutorial_complete with value of 1: \",\n",
    "                                df[df.game_stats_tutorial_complete == 1.].shape[0])\n",
    "print(f\"Number of game_stats_tutorial_complete with value of 0: \",\n",
    "                                df[df.game_stats_tutorial_complete == 0.].shape[0])\n",
    "print(f\"Number of game_stats_tutorial_complete with value of Nan: \",\n",
    "                                df.game_stats_tutorial_complete.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = [col for col in df if col.startswith('game_stats_xp')]\n",
    "for exp in experiences:\n",
    "    print(f\"Number of {exp} with value of Nan: \",\n",
    "                                df[df[exp].isna()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and describe dataframe with only tutorial complete is 1,\n",
    "# since we are just interested in people who finished tutorial\n",
    "df_completed_tutorial = df[df.game_stats_tutorial_complete == 1.]\n",
    "df_completed_tutorial.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.total_spend.describe())\n",
    "print(df_completed_tutorial.total_spend.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 8))\n",
    "# plt.title('Total spend')\n",
    "# plt.ylabel('Total spend')\n",
    "# plt.bar(np.arange(0,df_completed_tutorial.shape[0]), df_completed_tutorial['total_spend'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_completed_tutorial.plot(x='total_spend', y=['game_stats_xp', 'game_stats_xp1',\n",
    "#        'game_stats_xp2', 'game_stats_xp3',], kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates from dataframe\n",
    "df_completed_tutorial.drop_duplicates(inplace=True)\n",
    "df_completed_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nan values from dataframe\n",
    "print(\"Number of Nans for each column just with completed tutorial: \\n\", df_completed_tutorial.isna().sum())\n",
    "df_completed_tutorial.dropna(inplace=True)\n",
    "print(\"Number of Nans for each column just with completed tutorial: \\n\", df_completed_tutorial.isna().sum())\n",
    "# df_completed_tutorial.to_csv('./kabam_ds_interview/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corrMatrix = df_completed_tutorial.corr()\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very correated features like device_mem_i can be removed.\n",
    "print((corrMatrix>0.9).sum())\n",
    "# df_completed_tutorial.drop(columns=['device_mem_i', 'device_gmem_i',\n",
    "#                                     'device_mem_grouping_i', 'device_gmem_grouping_i'], inplace=True)\n",
    "df_completed_tutorial.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with string value and change them to categorical type for pandas\n",
    "categorical_columns = []\n",
    "for col in df_completed_tutorial.columns:\n",
    "    #print(col, df_completed_tutorial[col].dtype.name)\n",
    "    if df_completed_tutorial[col].dtype.name == 'object':\n",
    "        df_completed_tutorial[col] = df_completed_tutorial[col].astype('category')\n",
    "        categorical_columns.append(col)\n",
    "        \n",
    "print(\"categorical_columns: \\n\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change categorical columns to numerical\n",
    "for col in categorical_columns:\n",
    "    codes, unique = pd.factorize(df_completed_tutorial[col].values, sort=False, na_sentinel=- 1, size_hint=None)\n",
    "    df_completed_tutorial[col] = codes\n",
    "df_completed_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop game_stats_tutorial_complete since it is all 1.\n",
    "df_completed_tutorial.drop('game_stats_tutorial_complete', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classes based on total_spend column for classification mode\n",
    "# For regression, the continues values of total_spend will be used.\n",
    "if classification_mode:\n",
    "    if n_class == 5:\n",
    "        df_completed_tutorial.loc[df_completed_tutorial['total_spend'] <= 0, 'total_spend'] = 0\n",
    "        df_completed_tutorial['total_spend'] = np.where(df_completed_tutorial['total_spend'].between(1,100), 1,\n",
    "                                    df_completed_tutorial['total_spend'])\n",
    "        df_completed_tutorial['total_spend'] = np.where(df_completed_tutorial['total_spend'].between(101,200), 2,\n",
    "                                    df_completed_tutorial['total_spend'])\n",
    "        df_completed_tutorial['total_spend'] = np.where(df_completed_tutorial['total_spend'].between(201,300), 3,\n",
    "                                    df_completed_tutorial['total_spend'])\n",
    "        df_completed_tutorial.loc[df_completed_tutorial['total_spend'] > 300, 'total_spend'] = 4\n",
    "\n",
    "    if n_class == 3:\n",
    "        df_completed_tutorial.loc[df_completed_tutorial['total_spend'] <= 0, 'total_spend'] = 0\n",
    "        df_completed_tutorial['total_spend'] = np.where(df_completed_tutorial['total_spend'].between(1,250), 1,\n",
    "                                    df_completed_tutorial['total_spend'])\n",
    "        df_completed_tutorial.loc[df_completed_tutorial['total_spend'] > 250, 'total_spend'] = 2\n",
    "\n",
    "    else:\n",
    "        df_completed_tutorial.loc[df_completed_tutorial['total_spend'] <= 0, 'total_spend'] = 0\n",
    "        df_completed_tutorial.loc[df_completed_tutorial['total_spend'] > 0, 'total_spend'] = 1\n",
    "        \n",
    "    df_completed_tutorial['total_spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(df_completed_tutorial, random_state, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    df_completed_tutorial (dataframe): pd.DataFrame\n",
    "        dataframe with all the data\n",
    "    test_size (float):\n",
    "        proportion of data to be used for testing\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test (pd.dataframe for x and pd.Series for y)\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        df_completed_tutorial.loc[:, df_completed_tutorial.columns != 'total_spend'],\n",
    "                        df_completed_tutorial['total_spend'], test_size=test_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "    print(\"X_train.shape: \", X_train.shape)\n",
    "    print(\"X_test.shape: \", X_test.shape)\n",
    "    print(\"y_train.shape: \", y_train.shape)\n",
    "    print(\"y_test.shape: \", y_test.shape)\n",
    "\n",
    "    try:\n",
    "        print(\"Confirm changes are the same after shuffling: \",\n",
    "                                        df.loc[1266806][\"game_stats_xp2\"] == X_train.loc[1266806][\"game_stats_xp2\"])\n",
    "    except ValueError:\n",
    "        print(\"Specific selected Column is removed.\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Split dataframe into train and test\n",
    "X_train, X_test, y_train, y_test = data_splitter(df_completed_tutorial, random_state=42, test_size=0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with random forest based on feature importance\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "model.fit(X_train.values[-10000:,:], y_train.values[-10000:])\n",
    "\n",
    "# Show importance scores\n",
    "print(\"Feature importance: \", model.feature_importances_)\n",
    "names = X_train.columns\n",
    "ticks = [i for i in range(len(names))]\n",
    "\n",
    "# Sort features\n",
    "order_features = {}\n",
    "selected_features = []\n",
    "for name, value in zip(names, ticks):\n",
    "        order_features[name] = model.feature_importances_[value]\n",
    "sorted_features = {k: v for k, v in sorted(order_features.items(), key=lambda item: item[1])}\n",
    "print(\"sorted_features: \", sorted_features)\n",
    "\n",
    "# Select most important features\n",
    "for k, v in sorted_features.items():\n",
    "        if v >= 0.01:\n",
    "                selected_features.append(k)\n",
    "print('Candidate features: ', selected_features)\n",
    "\n",
    "selected_features.append('total_spend')\n",
    "df_completed_tutorial = df_completed_tutorial[selected_features]\n",
    "df_completed_tutorial.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into train and test with selected features\n",
    "X_train, X_test, y_train, y_test = data_splitter(df_completed_tutorial, random_state=45, test_size=0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train[X_train.columns] = scaler.transform(X_train)\n",
    "X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "if regression_mode:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(y_train.values.reshape(-1,1))\n",
    "    y_tr = scaler.transform(y_train.values.reshape(-1,1))\n",
    "    y_te = scaler.transform(y_test.values.reshape(-1,1))\n",
    "    y_train = pd.Series(data=y_tr.ravel(), index=y_train.index)\n",
    "    y_test = pd.Series(data=y_te.ravel(), index=y_test.index)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#plt.plot(X_train['game_stats_tutorial_complete_time'][:100000])\n",
    "plt.title('Total spend y_test')\n",
    "plt.ylabel('Total spend')\n",
    "plt.hist(y_test, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very imbalanced data. Mostly (around 98%) with 0 value (does not spend at all)\n",
    "print((y_train[y_train>0].shape[0] / y_train[y_train==0].shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling, downsampling, PCA, drop categorical columns and drop zero class\n",
    "if classification_mode:\n",
    "    if down_sample:\n",
    "        # class_1_above = []\n",
    "        # for i in y_train.unique():\n",
    "        #     print(f\"Class {i}: \", y_train[y_train == i].shape[0])\n",
    "        #     if i != 0:\n",
    "        #         class_1_above.append(y_train[y_train == i].shape[0])\n",
    "        # avg_number = np.ceil(np.mean(class_1_above))\n",
    "        # removal_numbers = int(y_train[y_train == 0].shape[0] - avg_number)\n",
    "        # index_removal = y_train[y_train == 0].sample(n=removal_numbers, replace=False).index\n",
    "        # y_train.drop(index_removal, inplace=True)\n",
    "        # X_train.drop(index_removal, inplace=True)\n",
    "        undersample = RandomUnderSampler(sampling_strategy=\"not minority\")\n",
    "        # fit and apply the transform\n",
    "        X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "        print(\"Downsampling is done.\")\n",
    "\n",
    "    if up_sample:\n",
    "        if up_sample == \"random_oversample\":\n",
    "            oversample = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "        if up_sample == \"smote_oversample\":\n",
    "            oversample = SMOTE(sampling_strategy=\"not majority\")\n",
    "        # fit and apply the transform\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "        print(\"Oversamling is done.\")\n",
    "\n",
    "if PCA_apply:\n",
    "    pca = PCA(n_components=PCA_apply)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    print(\"PCA done.\")\n",
    "\n",
    "if drop_categorical_cols:\n",
    "    try:\n",
    "        X_train = X_train.drop(columns=categorical_columns)\n",
    "        X_test = X_test.drop(columns=categorical_columns)\n",
    "        print(\"Categorical columns dropped.\")\n",
    "    except ValueError:\n",
    "        print(\"No categorical columns to drop. Check feature selection removed features.\")\n",
    "\n",
    "if drop_zero_calss:\n",
    "    if n_class >2 and classification_mode:\n",
    "        pass\n",
    "    else:\n",
    "        X_train = X_train[y_train != 0]\n",
    "        y_train = y_train[y_train != 0]\n",
    "        X_test = X_test[y_test != 0]\n",
    "        y_test = y_test[y_test != 0]\n",
    "        print(\"Zero class removed.\")\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how manu values are there in each class\n",
    "for i in y_train.unique():\n",
    "    print(f\"Class {i}: \", y_train[y_train == i].shape[0])\n",
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Plots the results of the model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_test: numpy ndarray\n",
    "        The actual values of the test set.\n",
    "    y_pred: numpy ndarray\n",
    "        The predicted values of the test set.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    # plt.scatter(np.arange(y_test.shape[0]), y_test, label='Actual')\n",
    "    # plt.scatter(np.arange(y_pred.shape[0]), y_pred, label='Predicted')\n",
    "    plt.hist(y_test, bins=20, label='Actual')\n",
    "    plt.hist(y_pred, bins=20, label='Predicted')\n",
    "    plt.legend()\n",
    "    plt.title('Predicted vs Actual')\n",
    "    plt.ylabel('Total spend')\n",
    "    plt.show()\n",
    "\n",
    "def regression_repot(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    compute errors for regression and plot results.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_test: numpy ndarray\n",
    "        The actual values of the test set.\n",
    "    y_pred: numpy ndarray\n",
    "        The predicted values of the test set.\n",
    "    \"\"\"\n",
    "    y_test_reverse = scaler.inverse_transform(y_test.values.reshape(-1,1))\n",
    "    y_pred_reverse = scaler.inverse_transform(y_pred.reshape(-1,1))\n",
    "    print(mean_squared_error(y_test_reverse, y_pred_reverse))\n",
    "    print(mean_absolute_error(y_test_reverse, y_pred_reverse))\n",
    "    plot_results(y_test_reverse, y_pred_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model for LSTM and Early stopping\n",
    "class TerminateOnBaseline(Callback):\n",
    "    \"\"\"Callback that terminates training when either acc or val_acc reaches a specified baseline\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor='val_loss', baseline=0.001):\n",
    "        super(TerminateOnBaseline, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(self.monitor)\n",
    "        if acc is not None:\n",
    "            if acc <= self.baseline:\n",
    "                print('Epoch %d: Reached baseline, terminating training' % (epoch))\n",
    "                self.model.stop_training = True\n",
    "save_best = keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML and DL Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression_mode:\n",
    "    elcv = ElasticNetCV(cv=5)\n",
    "    elcv.fit(X_train, y_train)\n",
    "    y_pred = elcv.predict(X_test)\n",
    "    regression_repot(y_test, y_pred)\n",
    "    \n",
    "    print(\"XGBoost\")\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "    params = {'subsample': 0.1,\n",
    "            'colsample_bytree': 0.1,\n",
    "            'objective': 'reg:linear',\n",
    "            'eval_metric': 'rmse',\n",
    "            'max_depth': 50,\n",
    "            'silent': 1,\n",
    "            'learning_rate': 0.1,\n",
    "            'nthread': 4,\n",
    "            'n_estimators': 3000,\n",
    "            }\n",
    "    bst = xgb.train(params, dtrain, 2)\n",
    "    y_pred = bst.predict(dtest)\n",
    "    regression_repot(y_test, y_pred)\n",
    "\n",
    "    print(\"Linear Regression\")\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    regression_repot(y_test, y_pred)\n",
    "\n",
    "    print(\"******\"*12)\n",
    "    print(\"Kernel Ridge\")\n",
    "    krr = KernelRidge(alpha=1.0)\n",
    "    krr.fit(X_train, y_train)\n",
    "    y_pred = krr.predict(X_test)\n",
    "    regression_repot(y_test, y_pred)\n",
    "\n",
    "    print(\"******\"*12)\n",
    "    reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "    models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "    print(models)\n",
    "    print(\"*******\"*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM model\n",
    "if regression_mode:\n",
    "    number_of_epochs = 5\n",
    "    batch_size = 128\n",
    "    validation_split = 0.2\n",
    "    x_train = np.expand_dims(X_train.values, axis=2)\n",
    "    x_test = np.expand_dims(X_test.values, axis=2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(x_train.shape[1],x_train.shape[2]), activation='relu', return_sequences = False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='sgd', loss='mse', metrics=['mae'])\n",
    "    model.summary()\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=number_of_epochs, shuffle=True, verbose=1,\n",
    "                        validation_split=validation_split,\n",
    "                        callbacks=[TerminateOnBaseline(monitor='val_loss', baseline=0.0005), save_best]).history\n",
    "\n",
    "    model = load_model('./model.h5')\n",
    "    y_pred = model.predict(x_test)\n",
    "    regression_repot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification_mode:\n",
    "    print(\"KNN\")\n",
    "    knn = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train.values.reshape(-1, 1))\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"******\"*12)\n",
    "    print(\"XGboost model\")\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "    params = {'subsample': 0.1,\n",
    "            'colsample_bytree': 0.1,\n",
    "            'objective': 'reg:linear',\n",
    "            'eval_metric': 'rmse',\n",
    "            'max_depth': 50,\n",
    "            'silent': 1,\n",
    "            'learning_rate': 0.1,\n",
    "            'nthread': 4,\n",
    "            'n_estimators': 3000,\n",
    "            }\n",
    "    bst = xgb.train(params, dtrain, 2)\n",
    "    y_pred = bst.predict(dtest)\n",
    "    y_pred = np.where(y_pred <= 0.5, 0, 1)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"******\"*12)\n",
    "    print(\"LSTM model\")\n",
    "    # Model configuration\n",
    "    additional_metrics = ['accuracy']\n",
    "    batch_size = 128\n",
    "    loss_function = CategoricalCrossentropy()\n",
    "    number_of_epochs = 5\n",
    "    optimizer = Adam()\n",
    "    validation_split = 0.2\n",
    "    verbosity_mode = 1\n",
    "    y_train_cat = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test_cat = tf.keras.utils.to_categorical(y_test)\n",
    "    # print(y_train.shape)\n",
    "    # Define the Keras model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    # model.add(Embedding(50000, 8, input_length = X_train.shape[1]))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(32, activation ='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(y_train_cat.shape[1], activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
    "    # Train the model\n",
    "    history = model.fit(np.expand_dims(X_train,2), y_train_cat, batch_size=batch_size,\n",
    "                epochs=number_of_epochs, verbose=verbosity_mode, validation_split=validation_split, shuffle=True,\n",
    "                callbacks=[TerminateOnBaseline(monitor='val_loss', baseline=0.0005), save_best]).history\n",
    "    # Give a summary\n",
    "    model.summary()\n",
    "    # Test the model after training\n",
    "    model = load_model('./model.h5')\n",
    "    test_results = model.evaluate(np.expand_dims(X_test, 2), y_test_cat, verbose=False)\n",
    "    print(f'Test results - Loss: {test_results[0]} - Accuracy: {100*test_results[1]}%')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test_cat.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    print(classification_report(y_test_cat.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    \n",
    "    print(\"******\"*12)\n",
    "    clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "    models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "    print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time taken: {time.time() - start} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
